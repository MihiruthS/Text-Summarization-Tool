# Text Summarization Tool

A lightweight and efficient text summarization tool leveraging the **llama.cpp** library for large language models, running entirely on your CPU. This tool provides a user-friendly interface built with **Gradio**, allowing seamless text summarization tasks using the **MaziyarPanahi/Llama-3.2-1B-Instruct-GGUF** model with Q4 quantization.

## Preview 
![image](https://github.com/user-attachments/assets/a8b52e55-beb7-4e45-af25-d0c64881a5f6)

## Features
- **Runs on CPU:** No GPU required, making it accessible for a wide range of systems.
- **Efficient Quantization:** Utilizes Q4 quantization for optimized performance and memory usage.
- **Interactive UI:** Built with Gradio for a smooth user experience.
- **High-Quality Summarization:** Powered by the Llama-3.2-1B-Instruct model for concise and coherent text summaries.

## Requirements
- Python 3.8+
- llama.cpp
- Gradio

For the full list of dependencies, refer to `requirements.txt`.

## Contributing
Contributions are welcome! Feel free to open an issue or submit a pull request with your improvements.

## Contact
For questions or suggestions, reach out via email at **mihiruth@gmail.com**.
